{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\compat\\_optional.py:135\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1206\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1178\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1142\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'openpyxl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SelectKBest, chi2\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Load Data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mWA_Fn-UseC_-Telco-Customer-Churn.xlsx\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mopenpyxl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1567\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28mself\u001b[39m.engine = engine\n\u001b[32m   1565\u001b[39m \u001b[38;5;28mself\u001b[39m.storage_options = storage_options\n\u001b[32m-> \u001b[39m\u001b[32m1567\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1568\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1570\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1571\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:552\u001b[39m, in \u001b[36mOpenpyxlReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;129m@doc\u001b[39m(storage_options=_shared_docs[\u001b[33m\"\u001b[39m\u001b[33mstorage_options\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    539\u001b[39m     engine_kwargs: \u001b[38;5;28mdict\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    540\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    541\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    542\u001b[39m \u001b[33;03m    Reader using openpyxl engine.\u001b[39;00m\n\u001b[32m    543\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    550\u001b[39m \u001b[33;03m        Arbitrary keyword arguments passed to excel engine.\u001b[39;00m\n\u001b[32m    551\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mopenpyxl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    553\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    554\u001b[39m         filepath_or_buffer,\n\u001b[32m    555\u001b[39m         storage_options=storage_options,\n\u001b[32m    556\u001b[39m         engine_kwargs=engine_kwargs,\n\u001b[32m    557\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\compat\\_optional.py:138\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Load Data\n",
    "data = pd.read_excel('WA_Fn-UseC_-Telco-Customer-Churn.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Statistik Deskriptif\n",
    "print(\"\\nStatistik Deskriptif:\")\n",
    "print(data.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Korelasi antar Fitur\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "# Drop kolom non-numerik sebelum mencari korelasi\n",
    "numeric_data = data.select_dtypes(include=['number'])\n",
    "correlation = numeric_data.corr()\n",
    "\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Heatmap Korelasi Antar Fitur')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Distribusi Churn\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='Churn', data=data)\n",
    "plt.title('Distribusi Churn')\n",
    "plt.xlabel('Churn (0 = No, 1 = Yes)')\n",
    "plt.ylabel('Jumlah Customer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Distribusi Fitur Numerik\n",
    "numeric_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "# Create a figure with subplots (1 row, 3 columns)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot each numeric feature\n",
    "for idx, feature in enumerate(numeric_features):\n",
    "    # Handle potential non-numeric data in TotalCharges\n",
    "    data[feature] = pd.to_numeric(data[feature], errors='coerce')\n",
    "    sns.histplot(data[feature].dropna(), kde=True, bins=50, ax=axes[idx])\n",
    "    axes[idx].set_title(f'Distribusi {feature}')\n",
    "    axes[idx].set_xlabel(feature)\n",
    "    axes[idx].set_ylabel('Jumlah')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Visualisasi Fitur Kategorikal\n",
    "categorical_features = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "                        'PhoneService', 'MultipleLines', 'InternetService',\n",
    "                        'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                        'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
    "                        'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
    "\n",
    "# Calculate the number of rows and columns for the subplot grid\n",
    "n_features = len(categorical_features)\n",
    "n_cols = 3  # Adjust the number of columns as needed\n",
    "n_rows = int(np.ceil(n_features / n_cols))  # Calculate rows needed\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 5, n_rows * 4))\n",
    "axes = axes.flatten()  # Flatten the 2D array of axes for easier iteration\n",
    "\n",
    "# Plot each categorical feature\n",
    "for idx, feature in enumerate(categorical_features):\n",
    "    sns.countplot(x=feature, data=data, order=data[feature].value_counts().index, ax=axes[idx])\n",
    "    axes[idx].set_title(f'Distribusi {feature}')\n",
    "    axes[idx].set_xlabel(feature)\n",
    "    axes[idx].set_ylabel('Jumlah Customer')\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for idx in range(len(categorical_features), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Check data types\n",
    "print(\"Data types:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# If columns are strings, clean and convert\n",
    "if data['MonthlyCharges'].dtype == 'object':\n",
    "    data['MonthlyCharges'] = data['MonthlyCharges'].str.replace(',', '.')\n",
    "    data['MonthlyCharges'] = data['MonthlyCharges'].astype(float)\n",
    "\n",
    "if data['TotalCharges'].dtype == 'object':\n",
    "    data['TotalCharges'] = data['TotalCharges'].str.replace(',', '.')\n",
    "    data['TotalCharges'] = data['TotalCharges'].replace(' ', np.nan)\n",
    "    data['TotalCharges'] = data['TotalCharges'].astype(float)\n",
    "\n",
    "# Check missing values before cleaning\n",
    "print(\"Missing values before cleaning:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Fill missing values in TotalCharges with median\n",
    "data['TotalCharges'].fillna(data['TotalCharges'].median(), inplace=True)\n",
    "\n",
    "# Check missing values after cleaning\n",
    "print(\"Missing values after cleaning:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Transformation\n",
    "# Encode categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "categorical_cols = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
    "                    'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                    'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n",
    "                    'PaperlessBilling', 'PaymentMethod', 'Churn']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    print(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Data Reduction\n",
    "# Pilih subset kolom yang penting (contoh: hapus customerID karena tidak relevan)\n",
    "data_reduced = data.drop(columns=['customerID'])\n",
    "print(data_reduced.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Data Discretization\n",
    "# Binning tenure menjadi kategori (contoh: New, Mid, Loyal)\n",
    "\n",
    "bins = [0, 12, 48, 72]\n",
    "labels = ['New', 'Mid', 'Loyal']\n",
    "data_reduced['tenure_group'] = pd.cut(data_reduced['tenure'], bins=bins, labels=labels)\n",
    "\n",
    "# Encode tenure_group\n",
    "data_reduced['tenure_group'] = le.fit_transform(data_reduced['tenure_group'])\n",
    "\n",
    "print(data_reduced['tenure_group'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Data Normalization\n",
    "# Normalisasi kolom numerik\n",
    "scaler = MinMaxScaler()\n",
    "numeric_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "data_reduced[numeric_cols] = scaler.fit_transform(data_reduced[numeric_cols])\n",
    "\n",
    "print(data_reduced[numeric_cols].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Feature Selection\n",
    "# Misalnya pilih 15 fitur terbaik\n",
    "X = data_reduced.drop('Churn', axis=1)\n",
    "y = data_reduced['Churn']\n",
    "\n",
    "selector = SelectKBest(score_func=chi2, k=20)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "selected_features = X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Data\n",
    "final_data = data_reduced[selected_features.tolist() + ['Churn']]\n",
    "\n",
    "# Save preprocessed data\n",
    "final_data.to_csv('preprocessed_data.csv', index=False)\n",
    "\n",
    "print(\"\\nData preprocessing complete! Output saved to 'preprocessed_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel, RFE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "import tensorflow as tf\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create 'models' directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "\n",
    "# Check for GPU availability\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    print(f\"GPU available: {physical_devices}\")\n",
    "    print(f\"Using GPU: {tf.test.gpu_device_name()}\")\n",
    "else:\n",
    "    print(\"No GPU available, using CPU\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "\n",
    "# Load preprocessed data\n",
    "try:\n",
    "    data = pd.read_csv('preprocessed_data.csv')\n",
    "    print(f\"Data loaded successfully with shape: {data.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'preprocessed_data.csv' not found.\")\n",
    "    exit(1)\n",
    "\n",
    "# Feature importance and selection function\n",
    "def select_features(X, y, n_features=None):\n",
    "    \"\"\"Select most important features using Random Forest feature importance\"\"\"\n",
    "    if n_features is None:\n",
    "        n_features = int(X.shape[1] * 0.8)  # Default to using 80% of features\n",
    "    \n",
    "    print(f\"Selecting top {n_features} features...\")\n",
    "    \n",
    "    # Use Random Forest to get feature importance\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    # Get feature importance\n",
    "    feature_importances = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': rf.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x='importance', y='feature', data=feature_importances.head(15))\n",
    "    plt.title('Top 15 Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/feature_importance.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Select top features\n",
    "    top_features = feature_importances.head(n_features)['feature'].tolist()\n",
    "    X_selected = X[top_features]\n",
    "    \n",
    "    print(f\"Selected features: {top_features}\")\n",
    "    return X_selected, top_features\n",
    "\n",
    "# Function to handle class imbalance\n",
    "def balance_data(X, y, method='smote_tomek'):\n",
    "    \"\"\"Balance dataset using SMOTE or SMOTETomek\"\"\"\n",
    "    print(f\"Balancing data using {method}...\")\n",
    "    if method == 'smote':\n",
    "        sampler = SMOTE(random_state=RANDOM_STATE)\n",
    "    elif method == 'smote_tomek':\n",
    "        sampler = SMOTETomek(random_state=RANDOM_STATE)\n",
    "    else:\n",
    "        raise ValueError(\"Method must be 'smote' or 'smote_tomek'\")\n",
    "    \n",
    "    X_balanced, y_balanced = sampler.fit_resample(X, y)\n",
    "    print(f\"Original class distribution: {pd.Series(y).value_counts().to_dict()}\")\n",
    "    print(f\"Balanced class distribution: {pd.Series(y_balanced).value_counts().to_dict()}\")\n",
    "    return X_balanced, y_balanced\n",
    "\n",
    "# Data exploration and prep\n",
    "print(\"\\n--- Data exploration ---\")\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"Class distribution: {data['Churn'].value_counts().to_dict()}\")\n",
    "print(f\"Class balance percentage: {data['Churn'].value_counts(normalize=True) * 100}\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "if missing_values.sum() > 0:\n",
    "    print(f\"Missing values found: \\n{missing_values[missing_values > 0]}\")\n",
    "    # Handle missing values (simple imputation)\n",
    "    data = data.fillna(data.median())\n",
    "\n",
    "# Detect outliers using IQR for numerical columns\n",
    "numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in numerical_cols:\n",
    "    if col == 'Churn':  # Skip target variable\n",
    "        continue\n",
    "    \n",
    "    Q1 = data[col].quantile(0.25)\n",
    "    Q3 = data[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = ((data[col] < lower_bound) | (data[col] > upper_bound)).sum()\n",
    "    if outliers > 0:\n",
    "        print(f\"Column {col} has {outliers} outliers\")\n",
    "        # Cap outliers instead of removing them\n",
    "        data[col] = np.where(data[col] < lower_bound, lower_bound, data[col])\n",
    "        data[col] = np.where(data[col] > upper_bound, upper_bound, data[col])\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('Churn', axis=1)\n",
    "y = data['Churn']\n",
    "\n",
    "# Feature selection\n",
    "X_selected, selected_features = select_features(X, y, n_features=int(X.shape[1] * 0.8))\n",
    "\n",
    "# Balance the dataset\n",
    "X_balanced, y_balanced = balance_data(X_selected, y, method='smote_tomek')\n",
    "\n",
    "# Split the data (stratified to maintain class distribution)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.2, random_state=RANDOM_STATE, stratify=y_balanced\n",
    ")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save scaler and selected features\n",
    "with open('models/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "with open('models/selected_features.pkl', 'wb') as f:\n",
    "    pickle.dump(selected_features, f)\n",
    "\n",
    "# Define models with hyperparameters tuned for ~85% accuracy\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        C=0.8, \n",
    "        penalty='l2',\n",
    "        solver='liblinear',\n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    "        subsample=0.8,\n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "    'SVM': SVC(\n",
    "        C=1.0,\n",
    "        kernel='rbf',\n",
    "        gamma='scale',\n",
    "        probability=True,\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "    'Decision Tree': DecisionTreeClassifier(\n",
    "        max_depth=6,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {\n",
    "    'Model': [],\n",
    "    'Train Accuracy': [],\n",
    "    'Test Accuracy': [],\n",
    "    'Gap': [],\n",
    "    'ROC AUC': []\n",
    "}\n",
    "\n",
    "# Train and evaluate traditional ML models\n",
    "print(\"\\n--- Training Machine Learning Models ---\")\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    gap = abs(train_accuracy - test_accuracy)\n",
    "    \n",
    "    # Calculate ROC AUC if model supports predict_proba\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_test_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_test_prob)\n",
    "    else:\n",
    "        roc_auc = \"N/A\"\n",
    "    \n",
    "    # Store results\n",
    "    results['Model'].append(name)\n",
    "    results['Train Accuracy'].append(train_accuracy)\n",
    "    results['Test Accuracy'].append(test_accuracy)\n",
    "    results['Gap'].append(gap)\n",
    "    results['ROC AUC'].append(roc_auc)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nClassification Report for {name} (Test Set):\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(f\"{name} Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"{name} Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"{name} Accuracy Gap: {gap:.4f}\")\n",
    "    if roc_auc != \"N/A\":\n",
    "        print(f\"{name} ROC AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    model_filename = f\"models/{name.replace(' ', '_')}_model.pkl\"\n",
    "    with open(model_filename, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"Model {name} saved as {model_filename}\")\n",
    "\n",
    "# Build optimized ANN\n",
    "print(\"\\n--- Training Neural Network Model ---\")\n",
    "def create_ann_model(input_shape):\n",
    "    \"\"\"Create an ANN model optimized for ~85% accuracy with minimal gap\"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(32, activation='relu', input_shape=(input_shape,), \n",
    "              kernel_regularizer=l1_l2(l1=0.001, l2=0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Dense(16, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create ANN model\n",
    "ann = create_ann_model(X_train_scaled.shape[1])\n",
    "ann.summary()\n",
    "\n",
    "# Define callbacks for ANN training\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    min_lr=0.0001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train ANN\n",
    "with tf.device('/GPU:0') if physical_devices else tf.device('/CPU:0'):\n",
    "    history = ann.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "# Evaluate ANN\n",
    "y_train_pred_ann = (ann.predict(X_train_scaled) > 0.5).astype(int).flatten()\n",
    "y_test_pred_ann = (ann.predict(X_test_scaled) > 0.5).astype(int).flatten()\n",
    "y_test_prob_ann = ann.predict(X_test_scaled).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "ann_train_accuracy = accuracy_score(y_train, y_train_pred_ann)\n",
    "ann_test_accuracy = accuracy_score(y_test, y_test_pred_ann)\n",
    "ann_gap = abs(ann_train_accuracy - ann_test_accuracy)\n",
    "ann_roc_auc = roc_auc_score(y_test, y_test_prob_ann)\n",
    "\n",
    "# Store ANN results\n",
    "results['Model'].append('ANN')\n",
    "results['Train Accuracy'].append(ann_train_accuracy)\n",
    "results['Test Accuracy'].append(ann_test_accuracy)\n",
    "results['Gap'].append(ann_gap)\n",
    "results['ROC AUC'].append(ann_roc_auc)\n",
    "\n",
    "# Print ANN results\n",
    "print(\"\\nClassification Report for ANN (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred_ann))\n",
    "print(f\"ANN Train Accuracy: {ann_train_accuracy:.4f}\")\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "print(f\"ANN Accuracy Gap: {ann_gap:.4f}\")\n",
    "print(f\"ANN ROC AUC: {ann_roc_auc:.4f}\")\n",
    "\n",
    "# Save ANN model\n",
    "ann.save('models/ANN_model.h5')\n",
    "print(\"ANN model saved as models/ANN_model.h5\")\n",
    "\n",
    "# Plot training history for ANN\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('ANN Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('ANN Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/ann_training_history.png')\n",
    "plt.close()\n",
    "\n",
    "# Create results DataFrame and add gap column\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('Test Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display comparison table\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(results_df)\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Test vs Train accuracy plot\n",
    "plt.subplot(2, 1, 1)\n",
    "results_melted = results_df.melt(id_vars='Model', value_vars=['Train Accuracy', 'Test Accuracy'],\n",
    "                                var_name='Dataset', value_name='Accuracy')\n",
    "sns.barplot(x='Model', y='Accuracy', hue='Dataset', data=results_melted)\n",
    "plt.title('Train vs Test Accuracy Comparison')\n",
    "plt.ylim(0.75, 1.0)  # Focus on the higher accuracy range\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Gap plot\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.barplot(x='Model', y='Gap', data=results_df)\n",
    "plt.title('Accuracy Gap (|Train - Test|)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/model_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# Find models with test accuracy close to 85%\n",
    "target_accuracy = 0.85\n",
    "best_models = results_df[\n",
    "    (results_df['Test Accuracy'] >= 0.83) & \n",
    "    (results_df['Test Accuracy'] <= 0.87) & \n",
    "    (results_df['Gap'] <= 0.05)\n",
    "].sort_values('Gap')\n",
    "\n",
    "if not best_models.empty:\n",
    "    best_model = best_models.iloc[0]\n",
    "    print(f\"\\nBest Model (closest to 85% with minimal gap): {best_model['Model']}\")\n",
    "    print(f\"Train Accuracy: {best_model['Train Accuracy']:.4f}\")\n",
    "    print(f\"Test Accuracy: {best_model['Test Accuracy']:.4f}\")\n",
    "    print(f\"Accuracy Gap: {best_model['Gap']:.4f}\")\n",
    "    if best_model['ROC AUC'] != \"N/A\":\n",
    "        print(f\"ROC AUC: {best_model['ROC AUC']:.4f}\")\n",
    "else:\n",
    "    # If no model is within the desired range, find the closest one\n",
    "    results_df['Distance_from_target'] = abs(results_df['Test Accuracy'] - target_accuracy)\n",
    "    best_model = results_df.sort_values(['Distance_from_target', 'Gap']).iloc[0]\n",
    "    print(f\"\\nBest Model (closest to target accuracy): {best_model['Model']}\")\n",
    "    print(f\"Train Accuracy: {best_model['Train Accuracy']:.4f}\")\n",
    "    print(f\"Test Accuracy: {best_model['Test Accuracy']:.4f}\")\n",
    "    print(f\"Accuracy Gap: {best_model['Gap']:.4f}\")\n",
    "    if best_model['ROC AUC'] != \"N/A\":\n",
    "        print(f\"ROC AUC: {best_model['ROC AUC']:.4f}\")\n",
    "\n",
    "print(\"\\nModel optimization completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add accuracy gap column for analysis\n",
    "results_df['Accuracy Gap'] = results_df['Train Accuracy'] - results_df['Test Accuracy']\n",
    "\n",
    "# Function to determine fitting status\n",
    "def determine_fit(train_acc, test_acc, gap, threshold_overfit=0.05, threshold_underfit=0.80):\n",
    "    if train_acc < threshold_underfit and test_acc < threshold_underfit:\n",
    "        return \"Underfitting\"\n",
    "    elif gap > threshold_overfit:\n",
    "        return \"Overfitting\"\n",
    "    else:\n",
    "        return \"Normal\"\n",
    "\n",
    "# Apply fitting status to each model\n",
    "results_df['Fit Status'] = results_df.apply(\n",
    "    lambda row: determine_fit(row['Train Accuracy'], row['Test Accuracy'], row['Accuracy Gap']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 1. Bar Plot for Train vs Test Accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "results_melted = results_df.melt(id_vars='Model', value_vars=['Train Accuracy', 'Test Accuracy'],\n",
    "                                 var_name='Dataset', value_name='Accuracy')\n",
    "sns.barplot(x='Model', y='Accuracy', hue='Dataset', data=results_melted)\n",
    "plt.title('Train vs Test Accuracy Comparison Across Models')\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Model')\n",
    "plt.legend(title='Dataset')\n",
    "plt.tight_layout()\n",
    "plt.savefig('train_test_accuracy_barplot.png')\n",
    "plt.close()\n",
    "\n",
    "# 2. Line Plot for Accuracy Gap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='Model', y='Accuracy Gap', data=results_df, marker='o', label='Accuracy Gap')\n",
    "plt.axhline(y=0.05, color='r', linestyle='--', label='Overfitting Threshold (5%)')\n",
    "plt.title('Accuracy Gap (Train - Test) Across Models')\n",
    "plt.ylabel('Accuracy Gap')\n",
    "plt.xlabel('Model')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('accuracy_gap_lineplot.png')\n",
    "plt.close()\n",
    "\n",
    "# 3. Plot ANN Training History (Loss and Accuracy Curves)\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Subplot for Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('ANN Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Subplot for Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('ANN Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ann_training_history.png')\n",
    "plt.close()\n",
    "\n",
    "# 4. Print Fitting Status and Explanation\n",
    "print(\"\\nFitting Status for Each Model:\")\n",
    "print(\"=\" * 50)\n",
    "for index, row in results_df.iterrows():\n",
    "    print(f\"Model: {row['Model']}\")\n",
    "    print(f\"Train Accuracy: {row['Train Accuracy']:.4f}\")\n",
    "    print(f\"Test Accuracy: {row['Test Accuracy']:.4f}\")\n",
    "    print(f\"Accuracy Gap: {row['Accuracy Gap']:.4f}\")\n",
    "    print(f\"Fit Status: {row['Fit Status']}\")\n",
    "    if row['Fit Status'] == 'Overfitting':\n",
    "        print(\"Explanation: The model is overfitting. It performs well on the training data but poorly on the test data, indicating it has learned noise or specific patterns in the training set that do not generalize.\")\n",
    "    elif row['Fit Status'] == 'Underfitting':\n",
    "        print(\"Explanation: The model is underfitting. Both training and test accuracies are low, indicating the model is too simple to capture the underlying patterns in the data.\")\n",
    "    else:\n",
    "        print(\"Explanation: The model has a normal fit. The training and test accuracies are close, and both are reasonably high, indicating good generalization.\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# 5. Additional Analysis for ANN (based on training history)\n",
    "print(\"\\nANN Training History Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "final_train_loss = history.history['loss'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "final_train_acc = history.history['accuracy'][-1]\n",
    "final_val_acc = history.history['val_accuracy'][-1]\n",
    "loss_gap = final_train_loss - final_val_loss\n",
    "acc_gap = final_train_acc - final_val_acc\n",
    "\n",
    "print(f\"Final Training Loss: {final_train_loss:.4f}\")\n",
    "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
    "print(f\"Final Training Accuracy: {final_train_acc:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
    "print(f\"Loss Gap (Train - Val): {loss_gap:.4f}\")\n",
    "print(f\"Accuracy Gap (Train - Val): {acc_gap:.4f}\")\n",
    "\n",
    "if final_val_loss > final_train_loss + 0.1 or acc_gap > 0.05:\n",
    "    print(\"ANN Fit Status: Overfitting\")\n",
    "    print(\"Explanation: The validation loss is significantly higher than the training loss, or the validation accuracy is much lower than the training accuracy, indicating overfitting.\")\n",
    "elif final_train_acc < 0.80 and final_val_acc < 0.80:\n",
    "    print(\"ANN Fit Status: Underfitting\")\n",
    "    print(\"Explanation: Both training and validation accuracies are low, indicating the ANN is too simple to capture the data patterns.\")\n",
    "else:\n",
    "    print(\"ANN Fit Status: Normal\")\n",
    "    print(\"Explanation: The training and validation metrics are close, and both are reasonably high, indicating good generalization.\")\n",
    "print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
